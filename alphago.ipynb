{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13411089,"sourceType":"datasetVersion","datasetId":8511255},{"sourceId":13452573,"sourceType":"datasetVersion","datasetId":8539106},{"sourceId":13826184,"sourceType":"datasetVersion","datasetId":8805180},{"sourceId":657151,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":496753,"modelId":512137}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# A replication of methods used in the AlphaGo paper \"Mastering the game of Go with deep neural networks and tree search","metadata":{}},{"cell_type":"code","source":"!pip install -q line_profiler\n%load_ext line_profiler\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:43:13.643973Z","iopub.execute_input":"2025-12-18T11:43:13.644762Z","iopub.status.idle":"2025-12-18T11:43:16.695256Z","shell.execute_reply.started":"2025-12-18T11:43:13.644729Z","shell.execute_reply":"2025-12-18T11:43:16.694495Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Game Environment\n\nA Python-based game env taken from https://github.com/maxpumperla/deep_learning_and_the_game_of_go\n","metadata":{}},{"cell_type":"markdown","source":"### Point, Player","metadata":{}},{"cell_type":"code","source":"import enum\nfrom collections import namedtuple\n\nclass Point(namedtuple('Point', 'row col')):\n    def neighbors(self):\n        return [\n            Point(self.row - 1, self.col),\n            Point(self.row + 1, self.col),\n            Point(self.row, self.col - 1),\n            Point(self.row, self.col + 1),\n        ]\nclass Player(enum.Enum):\n    black = 1\n    white = 2\n\n    @property\n    def other(self):\n        return Player.black if self == Player.white else Player.white","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:35:51.745764Z","iopub.execute_input":"2025-12-18T18:35:51.746717Z","iopub.status.idle":"2025-12-18T18:35:51.752954Z","shell.execute_reply.started":"2025-12-18T18:35:51.746688Z","shell.execute_reply":"2025-12-18T18:35:51.751994Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"### GameResult, Territory","metadata":{}},{"cell_type":"code","source":"from __future__ import absolute_import\nfrom collections import namedtuple\n\nclass Territory(object):\n    def __init__(self, territory_map):\n        self.num_black_territory = 0\n        self.num_white_territory = 0\n        self.num_black_stones = 0\n        self.num_white_stones = 0\n        self.num_dame = 0\n        self.dame_points = []\n        for point, status in territory_map.items():\n            if status == Player.black:\n                self.num_black_stones += 1\n            elif status == Player.white:\n                self.num_white_stones += 1\n            elif status == 'territory_b':\n                self.num_black_territory += 1\n            elif status == 'territory_w':\n                self.num_white_territory += 1\n            elif status == 'dame':\n                self.num_dame += 1\n                self.dame_points.append(point)\n\nclass GameResult(namedtuple('GameResult', 'b w komi')):\n    @property\n    def winner(self):\n        if self.b > self.w + self.komi:\n            return Player.black\n        if self.b < self.w + self.komi:\n            return Player.white\n        return None\n\n    @property\n    def winning_margin(self):\n        w = self.w + self.komi\n        return abs(self.b - w)\n\n    def __str__(self):\n        w = self.w + self.komi\n        if self.b > w:\n            return 'B+%.1f' % (self.b - w,)\n        return 'W+%.1f' % (w - self.b,)\n\ndef _collect_region(start_pos, board, visited=None):\n    if visited is None:\n        visited = {}\n    if start_pos in visited:\n        return [], set()\n    all_points = [start_pos]\n    all_borders = set()\n    visited[start_pos] = True\n    here = board.get(start_pos)\n    deltas = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n    for delta_r, delta_c in deltas:\n        next_p = Point(row=start_pos.row + delta_r, col=start_pos.col + delta_c)\n        if not board.is_on_grid(next_p):\n            continue\n        neighbor = board.get(next_p)\n        if neighbor == here:\n            points, borders = _collect_region(next_p, board, visited)\n            all_points += points\n            all_borders |= borders\n        else:\n            all_borders.add(neighbor)\n    return all_points, all_borders\n\ndef evaluate_territory(board):\n    status = {}\n    for r in range(1, board.num_rows + 1):\n        for c in range(1, board.num_cols + 1):\n            p = Point(row=r, col=c)\n            if p in status:\n                continue\n            stone = board.get(p)\n            if stone is not None:\n                status[p] = board.get(p)\n            else:\n                group, neighbors = _collect_region(p, board)\n                if len(neighbors) == 1:\n                    neighbor_stone = neighbors.pop()\n                    stone_str = 'b' if neighbor_stone == Player.black else 'w'\n                    fill_with = 'terrtory_' + stone_str\n                else:\n                    fill_with = 'dame'\n                for pos in group:\n                    status[pos] = fill_with\n    return Territory(status)\n\ndef compute_game_result(game_state):\n    territory = evaluate_territory(game_state.board)\n    return GameResult(\n        territory.num_black_territory + territory.num_black_stones,\n        territory.num_white_territory + territory.num_white_stones,\n        komi=7.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:02:30.165997Z","iopub.execute_input":"2025-12-18T18:02:30.166299Z","iopub.status.idle":"2025-12-18T18:02:30.181868Z","shell.execute_reply.started":"2025-12-18T18:02:30.166277Z","shell.execute_reply":"2025-12-18T18:02:30.180803Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### GameBoard, GameState, Move, GoString","metadata":{}},{"cell_type":"code","source":"import copy\n\nclass Board():\n    def __init__(self, num_rows, num_cols):\n        self.num_rows = num_rows\n        self.num_cols = num_cols\n        self._grid = {}\n        self._hash = EMPTY_BOARD\n\n    # replace string should be immutable, which means that it should return a new grid\n    def _replace_string(self, new_string):\n        for point in new_string.stones:\n            self._grid[point] = new_string\n\n    def _remove_string(self, string):\n        for point in string.stones:\n            for neighbor in point.neighbors():\n                neighbor_string = self._grid.get(neighbor)\n                if neighbor_string is None:\n                    continue\n                if neighbor_string is not string:\n                    self._replace_string(neighbor_string.with_liberty(point))\n            self._grid[point] = None\n            self._hash ^= HASH_CODE[point, string.color]\n\n    def zobrist_hash(self):\n        return self._hash\n\n    def place_stone(self, player, point):\n        assert self.is_on_grid(point)\n        assert self._grid.get(point) is None\n        adjacent_same_color = []\n        adjacent_opposite_color = []\n        liberties = []\n        for neighbor in point.neighbors():\n            if not self.is_on_grid(neighbor):\n                continue\n            neighbor_string = self._grid.get(neighbor)\n            if neighbor_string is None:\n                liberties.append(neighbor)\n            elif neighbor_string.color == player:\n                if neighbor_string not in adjacent_same_color:\n                    adjacent_same_color.append(neighbor_string)\n            else:\n                if neighbor_string not in adjacent_opposite_color:\n                    adjacent_opposite_color.append(neighbor_string)\n        new_string = GoString(player, [point], liberties)\n        for same_color_string in adjacent_same_color:\n            new_string = new_string.merged_with(same_color_string)\n        for new_string_point in new_string.stones:\n            self._grid[new_string_point] = new_string\n        self._hash ^= HASH_CODE[point, player]\n        for other_color_string in adjacent_opposite_color:\n            replacement = other_color_string.without_liberty(point)\n            if replacement.num_liberties:\n                self._replace_string(other_color_string.without_liberty(point))\n            else:\n                self._remove_string(other_color_string)\n\n    def is_on_grid(self, point):\n        return 1 <= point.row <= self.num_rows and \\\n            1 <= point.col <= self.num_cols\n\n    def get(self, point):\n        string = self._grid.get(point)\n        if string is None:\n            return None\n        return string.color\n\n    def get_go_string(self, point):\n        string = self._grid.get(point)\n        if string is None:\n            return None\n        return string\n\nclass Move():\n    def __init__(self, point=None, is_pass=False, is_resign=False):\n        assert (point is not None) ^ is_pass ^ is_resign\n        self.point = point\n        self.is_play = (self.point is not None)\n        self.is_pass = is_pass\n        self.is_resign = is_resign\n\n    @classmethod\n    def play(cls, point):\n        return Move(point=point)\n\n    @classmethod\n    def pass_turn(cls):\n        return Move(is_pass=True)\n\n    @classmethod\n    def resign(cls):\n        return Move(is_resign=True)\n\n# Chain of connected stones (used to e.g. efficiently check for liberties)\nclass GoString():\n    def __init__(self, color, stones, liberties):\n        self.color = color\n        self.stones = frozenset(stones)\n        self.liberties = frozenset(liberties)\n\n    def without_liberty(self, point):\n        new_liberties = self.liberties - set([point])\n        return GoString(self.color, self.stones, new_liberties)\n\n    def with_liberty(self, point):\n        new_liberties = self.liberties | set([point])\n        return GoString(self.color, self.stones, new_liberties)\n\n    def merged_with(self, go_string):\n        assert go_string.color == self.color\n        combined_stones = self.stones | go_string.stones\n        return GoString(\n            self.color,\n            combined_stones,\n            (self.liberties | go_string.liberties) - combined_stones\n        )\n\n    @property\n    def num_liberties(self):\n        return len(self.liberties)\n\n    def __eq__(self, other):\n        return isinstance(other, GoString) and \\\n            self.color == other.color and \\\n            self.stones == other.stones and \\\n            self.liberties == other.liberties\n\nclass GameState():\n    def __init__(self, board, next_player, previous, move):\n        self.board = board\n        self.next_player = next_player\n        self.previous_state = previous\n        if self.previous_state is None:\n            self.previous_states = frozenset()\n        else:\n            self.previous_states = frozenset(\n                previous.previous_states |\n                {(previous.next_player, previous.board.zobrist_hash())})\n        self.last_move = move\n\n    def apply_move(self, move):\n        if move.is_play:\n            next_board = copy.deepcopy(self.board)\n            next_board.place_stone(self.next_player, move.point)\n        else:\n            next_board = self.board\n        return GameState(next_board, self.next_player.other, self, move)\n\n    def is_over(self):\n        if self.last_move is None:\n            return False\n        if self.last_move.is_resign:\n            return True\n        second_last_move = self.previous_state.last_move\n        if second_last_move is None:\n            return False\n        return self.last_move.is_pass and second_last_move.is_pass\n\n    def is_move_self_capture(self, player, move):\n        if not move.is_play:\n            return False\n        next_board = copy.deepcopy(self.board)\n        next_board.place_stone(player, move.point)\n        new_string = next_board.get_go_string(move.point)\n        return new_string.num_liberties == 0\n\n    def is_valid_move(self, move):\n        if self.is_over():\n            return False\n        if move.is_pass or move.is_resign:\n            return True\n        return (\n            self.board.get(move.point) is None and\n            not self.is_move_self_capture(self.next_player, move) and\n            not self.does_move_violate_ko(self.next_player, move))\n    \n    def legal_moves(self):\n        if self.is_over():\n            return []\n        moves = []\n        for row in range(1, self.board.num_rows + 1):\n            for col in range(1, self.board.num_cols + 1):\n                move = Move.play(Point(row, col))\n                if self.is_valid_move(move):\n                    moves.append(move)\n        moves.append(Move.pass_turn())\n        moves.append(Move.resign())\n        return moves\n    \n    def winner(self):\n        if not self.is_over():\n            return None\n        if self.last_move.is_resign:\n            return self.next_player\n        game_result = compute_game_result(self)\n        return game_result.winner\n\n    @classmethod\n    def new_game(cls, board_size):\n        if isinstance(board_size, int):\n            board_size = (board_size, board_size)\n        board = Board(*board_size)\n        return GameState(board, Player.black, None, None)\n\n    @property\n    def situation(self):\n        return (self.next_player, self.board)\n\n    def does_move_violate_ko(self, player, move):\n        if not move.is_play:\n            return False\n        next_board = copy.deepcopy(self.board)\n        next_board.place_stone(player, move.point)\n        next_situation = (player.other, next_board.zobrist_hash())\n        return next_situation in self.previous_states","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:02:26.004539Z","iopub.execute_input":"2025-12-18T18:02:26.004886Z","iopub.status.idle":"2025-12-18T18:02:26.033284Z","shell.execute_reply.started":"2025-12-18T18:02:26.004862Z","shell.execute_reply":"2025-12-18T18:02:26.032213Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Zobrist Hash","metadata":{}},{"cell_type":"code","source":"import random\n\nMAX63 = 0x7fffffffffffffff\n\nHASH_CODE = {}\nEMPTY_BOARD = 0\n\nfor row in range(1, 20):\n    for col in range(1, 20):\n        for state in (1, 2):\n            code = random.randint(0, MAX63)\n            HASH_CODE[Point(row, col), state] = code\n\nprint(HASH_CODE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:43:18.916053Z","iopub.execute_input":"2025-12-18T18:43:18.916818Z","iopub.status.idle":"2025-12-18T18:43:18.925377Z","shell.execute_reply.started":"2025-12-18T18:43:18.916792Z","shell.execute_reply":"2025-12-18T18:43:18.924441Z"}},"outputs":[{"name":"stdout","text":"{(Point(row=1, col=1), 1): 4475682929734170013, (Point(row=1, col=1), 2): 2374906053581112065, (Point(row=1, col=2), 1): 4732034602522842698, (Point(row=1, col=2), 2): 2472343811693303469, (Point(row=1, col=3), 1): 7704380060705199105, (Point(row=1, col=3), 2): 2719748036203861695, (Point(row=1, col=4), 1): 2072031333159584271, (Point(row=1, col=4), 2): 3347024802860196666, (Point(row=1, col=5), 1): 8752855963753956208, (Point(row=1, col=5), 2): 3023607942245791684, (Point(row=1, col=6), 1): 6568443241487942297, (Point(row=1, col=6), 2): 8344536220281684196, (Point(row=1, col=7), 1): 7590280256247674005, (Point(row=1, col=7), 2): 1764585455744240403, (Point(row=1, col=8), 1): 785046941369861548, (Point(row=1, col=8), 2): 2398634138801741487, (Point(row=1, col=9), 1): 8527849142861235390, (Point(row=1, col=9), 2): 66359009297796696, (Point(row=1, col=10), 1): 4941132906820714375, (Point(row=1, col=10), 2): 4460880271995309121, (Point(row=1, col=11), 1): 1519086370751170034, (Point(row=1, col=11), 2): 4168509739590073795, (Point(row=1, col=12), 1): 4709993180308492791, (Point(row=1, col=12), 2): 8808887904000224540, (Point(row=1, col=13), 1): 7639217778654381123, (Point(row=1, col=13), 2): 7582572604654545333, (Point(row=1, col=14), 1): 497038396252806274, (Point(row=1, col=14), 2): 842966706540440639, (Point(row=1, col=15), 1): 1235809004760659635, (Point(row=1, col=15), 2): 5897365068353170050, (Point(row=1, col=16), 1): 801075618836746434, (Point(row=1, col=16), 2): 6703717829953959394, (Point(row=1, col=17), 1): 4045243472620058221, (Point(row=1, col=17), 2): 5814385160357864141, (Point(row=1, col=18), 1): 1032007755579098689, (Point(row=1, col=18), 2): 1572225945593427629, (Point(row=1, col=19), 1): 733678542835096541, (Point(row=1, col=19), 2): 3375928433516497026, (Point(row=2, col=1), 1): 8727675567281231014, (Point(row=2, col=1), 2): 3217563051131344824, (Point(row=2, col=2), 1): 2876226142852858627, (Point(row=2, col=2), 2): 4902400296536356267, (Point(row=2, col=3), 1): 1851377621393006060, (Point(row=2, col=3), 2): 7572943650793552772, (Point(row=2, col=4), 1): 2736164790056603551, (Point(row=2, col=4), 2): 1914881772638930029, (Point(row=2, col=5), 1): 8609313114368549700, (Point(row=2, col=5), 2): 9018816620879949915, (Point(row=2, col=6), 1): 2317846864646158750, (Point(row=2, col=6), 2): 5350610368987879270, (Point(row=2, col=7), 1): 8326919941251787137, (Point(row=2, col=7), 2): 1720120105799603493, (Point(row=2, col=8), 1): 4737049008038300943, (Point(row=2, col=8), 2): 6746318670497932015, (Point(row=2, col=9), 1): 8510008306528253185, (Point(row=2, col=9), 2): 4719140717700055626, (Point(row=2, col=10), 1): 3096329213008853793, (Point(row=2, col=10), 2): 1882767107837249009, (Point(row=2, col=11), 1): 6815226693535362960, (Point(row=2, col=11), 2): 6371653951528084608, (Point(row=2, col=12), 1): 5717359131238471666, (Point(row=2, col=12), 2): 4771635893804852262, (Point(row=2, col=13), 1): 1138363655996123327, (Point(row=2, col=13), 2): 7328130817109334355, (Point(row=2, col=14), 1): 8061884623671864060, (Point(row=2, col=14), 2): 5531928194226218644, (Point(row=2, col=15), 1): 1447570139555830423, (Point(row=2, col=15), 2): 6494768927084789555, (Point(row=2, col=16), 1): 6901360107132373318, (Point(row=2, col=16), 2): 7834535875602892826, (Point(row=2, col=17), 1): 7493246103836806751, (Point(row=2, col=17), 2): 249888170774433577, (Point(row=2, col=18), 1): 3260112981016143150, (Point(row=2, col=18), 2): 4854563175641269897, (Point(row=2, col=19), 1): 3938168775371564194, (Point(row=2, col=19), 2): 3682018817530301735, (Point(row=3, col=1), 1): 7361129097103784669, (Point(row=3, col=1), 2): 307192601485806248, (Point(row=3, col=2), 1): 4823088176145850714, (Point(row=3, col=2), 2): 7854402864256747525, (Point(row=3, col=3), 1): 3321968902464690041, (Point(row=3, col=3), 2): 5189031699417723823, (Point(row=3, col=4), 1): 7668608494995295895, (Point(row=3, col=4), 2): 6663738180779344572, (Point(row=3, col=5), 1): 7228562728410881685, (Point(row=3, col=5), 2): 7185418944158104064, (Point(row=3, col=6), 1): 5739611112285042741, (Point(row=3, col=6), 2): 687974222422025954, (Point(row=3, col=7), 1): 4289033597512957308, (Point(row=3, col=7), 2): 6927938784591565328, (Point(row=3, col=8), 1): 5722477083240019332, (Point(row=3, col=8), 2): 8215941596787917417, (Point(row=3, col=9), 1): 2277245727482512295, (Point(row=3, col=9), 2): 3090326413533759369, (Point(row=3, col=10), 1): 8175513216876161166, (Point(row=3, col=10), 2): 9059192082740562916, (Point(row=3, col=11), 1): 5785524197661234814, (Point(row=3, col=11), 2): 3849539325144149208, (Point(row=3, col=12), 1): 397260066022896662, (Point(row=3, col=12), 2): 1050567913999755998, (Point(row=3, col=13), 1): 4224938838885281649, (Point(row=3, col=13), 2): 2791416339364782757, (Point(row=3, col=14), 1): 6005806753371551319, (Point(row=3, col=14), 2): 6552871591754682761, (Point(row=3, col=15), 1): 6856057493610620221, (Point(row=3, col=15), 2): 126552387301935833, (Point(row=3, col=16), 1): 948712825570800324, (Point(row=3, col=16), 2): 1081608146055508628, (Point(row=3, col=17), 1): 4676794893387603402, (Point(row=3, col=17), 2): 2501256405468681111, (Point(row=3, col=18), 1): 1306600462055291769, (Point(row=3, col=18), 2): 2870320790540213872, (Point(row=3, col=19), 1): 5413376514546938168, (Point(row=3, col=19), 2): 962313171293086653, (Point(row=4, col=1), 1): 2067645280912396241, (Point(row=4, col=1), 2): 4390827034745147754, (Point(row=4, col=2), 1): 4692938487129895276, (Point(row=4, col=2), 2): 7726638853182035729, (Point(row=4, col=3), 1): 6670713855055970883, (Point(row=4, col=3), 2): 7100204338011970535, (Point(row=4, col=4), 1): 2500342530906028713, (Point(row=4, col=4), 2): 6492148302699810838, (Point(row=4, col=5), 1): 379455146187210133, (Point(row=4, col=5), 2): 7993008250644826281, (Point(row=4, col=6), 1): 7108868056773462887, (Point(row=4, col=6), 2): 4473525544901583091, (Point(row=4, col=7), 1): 4258431334887121392, (Point(row=4, col=7), 2): 534163130197979742, (Point(row=4, col=8), 1): 8086366911695117844, (Point(row=4, col=8), 2): 2202714944590716601, (Point(row=4, col=9), 1): 2223655338650931523, (Point(row=4, col=9), 2): 7064177752801206296, (Point(row=4, col=10), 1): 5429240711031168007, (Point(row=4, col=10), 2): 8965233951627879274, (Point(row=4, col=11), 1): 3338642226012253090, (Point(row=4, col=11), 2): 7277168592938970424, (Point(row=4, col=12), 1): 8994351163891411326, (Point(row=4, col=12), 2): 4529764604641121518, (Point(row=4, col=13), 1): 8283306335236551055, (Point(row=4, col=13), 2): 1906465227828786212, (Point(row=4, col=14), 1): 8162805115955652256, (Point(row=4, col=14), 2): 1769897501368931393, (Point(row=4, col=15), 1): 8373222224323504995, (Point(row=4, col=15), 2): 150747173333095811, (Point(row=4, col=16), 1): 4958937012990660093, (Point(row=4, col=16), 2): 2520545510188171391, (Point(row=4, col=17), 1): 7359573848710404328, (Point(row=4, col=17), 2): 2670620435124104395, (Point(row=4, col=18), 1): 2974427955398420855, (Point(row=4, col=18), 2): 7921080890913200028, (Point(row=4, col=19), 1): 7051330285071567606, (Point(row=4, col=19), 2): 1802960230172235428, (Point(row=5, col=1), 1): 1596793497761900425, (Point(row=5, col=1), 2): 1597323840169974152, (Point(row=5, col=2), 1): 1075392866400741042, (Point(row=5, col=2), 2): 2672913911500671614, (Point(row=5, col=3), 1): 5353505293062568501, (Point(row=5, col=3), 2): 1526865445155835342, (Point(row=5, col=4), 1): 4348791869279350890, (Point(row=5, col=4), 2): 9004116108358881032, (Point(row=5, col=5), 1): 6202794453113045955, (Point(row=5, col=5), 2): 8155049394883930349, (Point(row=5, col=6), 1): 8557818720615973537, (Point(row=5, col=6), 2): 1175145336049140372, (Point(row=5, col=7), 1): 8925796332015994222, (Point(row=5, col=7), 2): 7402945694911075657, (Point(row=5, col=8), 1): 848179621130106713, (Point(row=5, col=8), 2): 2352502600387001131, (Point(row=5, col=9), 1): 3090081432856754777, (Point(row=5, col=9), 2): 7623088812181170957, (Point(row=5, col=10), 1): 7015378244808909188, (Point(row=5, col=10), 2): 8532917720447284947, (Point(row=5, col=11), 1): 4282818766020553584, (Point(row=5, col=11), 2): 2397230000697905097, (Point(row=5, col=12), 1): 8969680061550314133, (Point(row=5, col=12), 2): 104258439330366895, (Point(row=5, col=13), 1): 2037687547409406409, (Point(row=5, col=13), 2): 9159974546246468028, (Point(row=5, col=14), 1): 9095356116780467797, (Point(row=5, col=14), 2): 6486069700623170052, (Point(row=5, col=15), 1): 3121019486068446104, (Point(row=5, col=15), 2): 5481177074624644314, (Point(row=5, col=16), 1): 1396035564340496179, (Point(row=5, col=16), 2): 5104407789049809299, (Point(row=5, col=17), 1): 4864672540750732658, (Point(row=5, col=17), 2): 1693295225700621490, (Point(row=5, col=18), 1): 4992342163259284123, (Point(row=5, col=18), 2): 852237852539428146, (Point(row=5, col=19), 1): 6821734324861128610, (Point(row=5, col=19), 2): 4141037101596262315, (Point(row=6, col=1), 1): 2656412478222612900, (Point(row=6, col=1), 2): 6980376643998352930, (Point(row=6, col=2), 1): 8933775194282957951, (Point(row=6, col=2), 2): 7751770410734620071, (Point(row=6, col=3), 1): 2022040527399876785, (Point(row=6, col=3), 2): 7503640893444391582, (Point(row=6, col=4), 1): 7213024629152728881, (Point(row=6, col=4), 2): 8833809643840779514, (Point(row=6, col=5), 1): 229748509122398810, (Point(row=6, col=5), 2): 1111919066798455025, (Point(row=6, col=6), 1): 2397035824241363145, (Point(row=6, col=6), 2): 5291626648688544357, (Point(row=6, col=7), 1): 3081111322469114299, (Point(row=6, col=7), 2): 5980020607305262943, (Point(row=6, col=8), 1): 141124717264541564, (Point(row=6, col=8), 2): 2580526246809313395, (Point(row=6, col=9), 1): 2665490302995069885, (Point(row=6, col=9), 2): 6890286308973329960, (Point(row=6, col=10), 1): 5289396047732404767, (Point(row=6, col=10), 2): 7542282977992957329, (Point(row=6, col=11), 1): 363224405577028623, (Point(row=6, col=11), 2): 2548025029019711895, (Point(row=6, col=12), 1): 9121201538099851850, (Point(row=6, col=12), 2): 7677421214039516497, (Point(row=6, col=13), 1): 5106411261340086847, (Point(row=6, col=13), 2): 2312766081074611493, (Point(row=6, col=14), 1): 3269742662639747421, (Point(row=6, col=14), 2): 2181600480486819333, (Point(row=6, col=15), 1): 7483458184733367008, (Point(row=6, col=15), 2): 6405887559016392892, (Point(row=6, col=16), 1): 7709097639592165580, (Point(row=6, col=16), 2): 3022792110552942763, (Point(row=6, col=17), 1): 9031382174687977216, (Point(row=6, col=17), 2): 1468739290595156765, (Point(row=6, col=18), 1): 5420942489954741659, (Point(row=6, col=18), 2): 8600554287967087331, (Point(row=6, col=19), 1): 1799834843526787693, (Point(row=6, col=19), 2): 4631229739799898962, (Point(row=7, col=1), 1): 2373849704429144154, (Point(row=7, col=1), 2): 4807603392459168995, (Point(row=7, col=2), 1): 2642801984735067829, (Point(row=7, col=2), 2): 1390295908968808649, (Point(row=7, col=3), 1): 1173784465466101961, (Point(row=7, col=3), 2): 6265006111409686526, (Point(row=7, col=4), 1): 7827083451241096506, (Point(row=7, col=4), 2): 5776847087374893272, (Point(row=7, col=5), 1): 2927986449808589256, (Point(row=7, col=5), 2): 7579061171328582522, (Point(row=7, col=6), 1): 5397221499935340077, (Point(row=7, col=6), 2): 3187435069260809984, (Point(row=7, col=7), 1): 6816562974349493691, (Point(row=7, col=7), 2): 4128471562204336499, (Point(row=7, col=8), 1): 7524150506806248150, (Point(row=7, col=8), 2): 5006792649175974440, (Point(row=7, col=9), 1): 5274222992709230985, (Point(row=7, col=9), 2): 7127197703138685230, (Point(row=7, col=10), 1): 4117833775040730200, (Point(row=7, col=10), 2): 8125997134954092441, (Point(row=7, col=11), 1): 2628745466275825343, (Point(row=7, col=11), 2): 5062568051788555678, (Point(row=7, col=12), 1): 560710595749465061, (Point(row=7, col=12), 2): 7933830140818907891, (Point(row=7, col=13), 1): 2790436115416968442, (Point(row=7, col=13), 2): 911943703533360277, (Point(row=7, col=14), 1): 9128776134969493311, (Point(row=7, col=14), 2): 2193624886625025671, (Point(row=7, col=15), 1): 8914948240818530638, (Point(row=7, col=15), 2): 5668301820346499375, (Point(row=7, col=16), 1): 3728651883746271990, (Point(row=7, col=16), 2): 4037174044599788722, (Point(row=7, col=17), 1): 8870055014634498042, (Point(row=7, col=17), 2): 1403117838730825474, (Point(row=7, col=18), 1): 6713404016491653040, (Point(row=7, col=18), 2): 8130451888989645753, (Point(row=7, col=19), 1): 974959429150338180, (Point(row=7, col=19), 2): 7288826348274776186, (Point(row=8, col=1), 1): 687924731407762112, (Point(row=8, col=1), 2): 8314563730862638905, (Point(row=8, col=2), 1): 4029908107026032585, (Point(row=8, col=2), 2): 1593961736219477531, (Point(row=8, col=3), 1): 6555423531348339868, (Point(row=8, col=3), 2): 3129544729022882683, (Point(row=8, col=4), 1): 4426146954717897089, (Point(row=8, col=4), 2): 5906872258185779062, (Point(row=8, col=5), 1): 4041640901721853125, (Point(row=8, col=5), 2): 5455213489676717756, (Point(row=8, col=6), 1): 8845176021497064857, (Point(row=8, col=6), 2): 7833459355535029945, (Point(row=8, col=7), 1): 5501249458364958210, (Point(row=8, col=7), 2): 8401024921927367845, (Point(row=8, col=8), 1): 8061160657727918378, (Point(row=8, col=8), 2): 6024004726838753770, (Point(row=8, col=9), 1): 6828122837879809754, (Point(row=8, col=9), 2): 2251696773403848749, (Point(row=8, col=10), 1): 711176066186551974, (Point(row=8, col=10), 2): 4528019373906455559, (Point(row=8, col=11), 1): 7039775945694229626, (Point(row=8, col=11), 2): 2208062930524788488, (Point(row=8, col=12), 1): 7915137340477248488, (Point(row=8, col=12), 2): 6032621450682327292, (Point(row=8, col=13), 1): 231429483846720818, (Point(row=8, col=13), 2): 7290695015372559345, (Point(row=8, col=14), 1): 911841645330556010, (Point(row=8, col=14), 2): 378648393887758629, (Point(row=8, col=15), 1): 2560896211260769410, (Point(row=8, col=15), 2): 2824077448153997575, (Point(row=8, col=16), 1): 5085093533403063945, (Point(row=8, col=16), 2): 759696877836335032, (Point(row=8, col=17), 1): 6813588397373345420, (Point(row=8, col=17), 2): 2927331425831753871, (Point(row=8, col=18), 1): 193953742793838349, (Point(row=8, col=18), 2): 5738656096598964798, (Point(row=8, col=19), 1): 7243663075431817091, (Point(row=8, col=19), 2): 8031058838778579646, (Point(row=9, col=1), 1): 517860226991852608, (Point(row=9, col=1), 2): 6784700362447134757, (Point(row=9, col=2), 1): 5532890393099297649, (Point(row=9, col=2), 2): 7537437261605289224, (Point(row=9, col=3), 1): 2624828296886760325, (Point(row=9, col=3), 2): 7112420873935602913, (Point(row=9, col=4), 1): 4334885406431441770, (Point(row=9, col=4), 2): 2677281072811474200, (Point(row=9, col=5), 1): 3735861102922079618, (Point(row=9, col=5), 2): 1633152554745439739, (Point(row=9, col=6), 1): 7149658924713363136, (Point(row=9, col=6), 2): 915511554829978643, (Point(row=9, col=7), 1): 5790928259556734998, (Point(row=9, col=7), 2): 8826614962610402041, (Point(row=9, col=8), 1): 3753970038545679922, (Point(row=9, col=8), 2): 7970044602192157248, (Point(row=9, col=9), 1): 3569544040286228089, (Point(row=9, col=9), 2): 5907917004358480928, (Point(row=9, col=10), 1): 55112251416388165, (Point(row=9, col=10), 2): 1829322532904922841, (Point(row=9, col=11), 1): 8213766332478905561, (Point(row=9, col=11), 2): 2677571697742536650, (Point(row=9, col=12), 1): 121848011400867208, (Point(row=9, col=12), 2): 3605590518550927237, (Point(row=9, col=13), 1): 4627702314391575149, (Point(row=9, col=13), 2): 6241322777519260754, (Point(row=9, col=14), 1): 4852182237471840979, (Point(row=9, col=14), 2): 2867754936503331906, (Point(row=9, col=15), 1): 7006176600798260520, (Point(row=9, col=15), 2): 637197199983784605, (Point(row=9, col=16), 1): 5587448071282517202, (Point(row=9, col=16), 2): 2464333227115392744, (Point(row=9, col=17), 1): 9147952854586197483, (Point(row=9, col=17), 2): 5573736187677456254, (Point(row=9, col=18), 1): 5554725640761123407, (Point(row=9, col=18), 2): 4316689569177684652, (Point(row=9, col=19), 1): 3812751661457548298, (Point(row=9, col=19), 2): 2397729392560922432, (Point(row=10, col=1), 1): 5676707947204307587, (Point(row=10, col=1), 2): 2406068688016813889, (Point(row=10, col=2), 1): 5543242558371839437, (Point(row=10, col=2), 2): 5242050233662868413, (Point(row=10, col=3), 1): 5616897034900917639, (Point(row=10, col=3), 2): 734710068376707922, (Point(row=10, col=4), 1): 7457794503336023298, (Point(row=10, col=4), 2): 1097718506375039647, (Point(row=10, col=5), 1): 5814037945233893526, (Point(row=10, col=5), 2): 9023921041927939820, (Point(row=10, col=6), 1): 9021820859979161412, (Point(row=10, col=6), 2): 3132159924088037228, (Point(row=10, col=7), 1): 1815369304634573161, (Point(row=10, col=7), 2): 5492087549947731664, (Point(row=10, col=8), 1): 1160227738867594170, (Point(row=10, col=8), 2): 4571342435322070199, (Point(row=10, col=9), 1): 815795709289704524, (Point(row=10, col=9), 2): 2988197864309370029, (Point(row=10, col=10), 1): 7931802159313535574, (Point(row=10, col=10), 2): 7606513515844351413, (Point(row=10, col=11), 1): 6516540067845236901, (Point(row=10, col=11), 2): 6006114110932713256, (Point(row=10, col=12), 1): 6013238697806046921, (Point(row=10, col=12), 2): 2470347190747490155, (Point(row=10, col=13), 1): 6778898828668181057, (Point(row=10, col=13), 2): 4790799113133410085, (Point(row=10, col=14), 1): 7550179504670500995, (Point(row=10, col=14), 2): 1765913453010848670, (Point(row=10, col=15), 1): 7461160991498280096, (Point(row=10, col=15), 2): 6472254172338091708, (Point(row=10, col=16), 1): 1321644860559097287, (Point(row=10, col=16), 2): 8408482917344162915, (Point(row=10, col=17), 1): 98439846448221931, (Point(row=10, col=17), 2): 612074442914609649, (Point(row=10, col=18), 1): 482069529970897385, (Point(row=10, col=18), 2): 6640189020688974194, (Point(row=10, col=19), 1): 8200232937697127033, (Point(row=10, col=19), 2): 1943228755913469621, (Point(row=11, col=1), 1): 5668438137428892423, (Point(row=11, col=1), 2): 8911445051496842761, (Point(row=11, col=2), 1): 6592998010184599062, (Point(row=11, col=2), 2): 4130712526249051796, (Point(row=11, col=3), 1): 2842210304291985635, (Point(row=11, col=3), 2): 7046233742724961673, (Point(row=11, col=4), 1): 4000092356072703243, (Point(row=11, col=4), 2): 558571407050033393, (Point(row=11, col=5), 1): 8199678776686217905, (Point(row=11, col=5), 2): 158983074835194544, (Point(row=11, col=6), 1): 6937949856412361205, (Point(row=11, col=6), 2): 1459918365589280364, (Point(row=11, col=7), 1): 2533923756676670561, (Point(row=11, col=7), 2): 4343867823443995945, (Point(row=11, col=8), 1): 6670864294819648696, (Point(row=11, col=8), 2): 4539125211471701954, (Point(row=11, col=9), 1): 331872983985544696, (Point(row=11, col=9), 2): 4216437778128071492, (Point(row=11, col=10), 1): 1796360456609326410, (Point(row=11, col=10), 2): 7789538046970416636, (Point(row=11, col=11), 1): 3858398815961155921, (Point(row=11, col=11), 2): 4809604775734388819, (Point(row=11, col=12), 1): 5062602376311409026, (Point(row=11, col=12), 2): 1091633782492030493, (Point(row=11, col=13), 1): 6939802811305349193, (Point(row=11, col=13), 2): 7796489735012962390, (Point(row=11, col=14), 1): 6828569163417008114, (Point(row=11, col=14), 2): 847134831564808289, (Point(row=11, col=15), 1): 7883862468822536584, (Point(row=11, col=15), 2): 486810301161103202, (Point(row=11, col=16), 1): 8060616728676736275, (Point(row=11, col=16), 2): 7989098086462412838, (Point(row=11, col=17), 1): 8137367145294119202, (Point(row=11, col=17), 2): 6605463306969944083, (Point(row=11, col=18), 1): 8195082398719963213, (Point(row=11, col=18), 2): 1911338925852496977, (Point(row=11, col=19), 1): 2841773494486938569, (Point(row=11, col=19), 2): 7825261132594651847, (Point(row=12, col=1), 1): 6680896806097173319, (Point(row=12, col=1), 2): 3809905943744261250, (Point(row=12, col=2), 1): 6877726709518267378, (Point(row=12, col=2), 2): 6712937056052823271, (Point(row=12, col=3), 1): 5932462744876696875, (Point(row=12, col=3), 2): 2633133266998208237, (Point(row=12, col=4), 1): 491790698306422545, (Point(row=12, col=4), 2): 1256459827192146911, (Point(row=12, col=5), 1): 5597258530524861192, (Point(row=12, col=5), 2): 6385974227432138020, (Point(row=12, col=6), 1): 1754140813891033196, (Point(row=12, col=6), 2): 354268707401428518, (Point(row=12, col=7), 1): 2845724195762379992, (Point(row=12, col=7), 2): 8096047619170688477, (Point(row=12, col=8), 1): 730183298735227522, (Point(row=12, col=8), 2): 3261331084396323600, (Point(row=12, col=9), 1): 4946578859539652401, (Point(row=12, col=9), 2): 9056600587381383945, (Point(row=12, col=10), 1): 5351914875168785632, (Point(row=12, col=10), 2): 4451374988873825482, (Point(row=12, col=11), 1): 3889491679115173502, (Point(row=12, col=11), 2): 5659747759279291093, (Point(row=12, col=12), 1): 8475935893827164292, (Point(row=12, col=12), 2): 8841740969844135410, (Point(row=12, col=13), 1): 3750788255939968610, (Point(row=12, col=13), 2): 1478820656366314395, (Point(row=12, col=14), 1): 5494579082451970181, (Point(row=12, col=14), 2): 2509386274955792025, (Point(row=12, col=15), 1): 8435153662555042018, (Point(row=12, col=15), 2): 4551411704102478976, (Point(row=12, col=16), 1): 2615237507685925179, (Point(row=12, col=16), 2): 1035832269676307334, (Point(row=12, col=17), 1): 5847410927243034570, (Point(row=12, col=17), 2): 4733845381050352464, (Point(row=12, col=18), 1): 6135542548613801643, (Point(row=12, col=18), 2): 426508049360686181, (Point(row=12, col=19), 1): 3113366605072827532, (Point(row=12, col=19), 2): 7809910992529625113, (Point(row=13, col=1), 1): 485953349763287869, (Point(row=13, col=1), 2): 4350907532382369199, (Point(row=13, col=2), 1): 6312684264017309528, (Point(row=13, col=2), 2): 7230110047149547122, (Point(row=13, col=3), 1): 349258605814217095, (Point(row=13, col=3), 2): 2635578678171734753, (Point(row=13, col=4), 1): 3065139906450085643, (Point(row=13, col=4), 2): 3035269087584375703, (Point(row=13, col=5), 1): 878213544949557298, (Point(row=13, col=5), 2): 8283503744921290859, (Point(row=13, col=6), 1): 8192295311685047611, (Point(row=13, col=6), 2): 1555161790589108065, (Point(row=13, col=7), 1): 8332925699112149539, (Point(row=13, col=7), 2): 4256805875445334662, (Point(row=13, col=8), 1): 1178099719253353365, (Point(row=13, col=8), 2): 6819347804681836772, (Point(row=13, col=9), 1): 1316867409039527653, (Point(row=13, col=9), 2): 6849900003053017365, (Point(row=13, col=10), 1): 1292049555794996277, (Point(row=13, col=10), 2): 4724819120474212134, (Point(row=13, col=11), 1): 1926469303136497845, (Point(row=13, col=11), 2): 5517224131857582957, (Point(row=13, col=12), 1): 1917197006085726033, (Point(row=13, col=12), 2): 1883720638201937347, (Point(row=13, col=13), 1): 153911913719802540, (Point(row=13, col=13), 2): 6355782055737290976, (Point(row=13, col=14), 1): 9056328363280255644, (Point(row=13, col=14), 2): 1755598632413138248, (Point(row=13, col=15), 1): 6531807636793446049, (Point(row=13, col=15), 2): 837321409251152388, (Point(row=13, col=16), 1): 6727857981624116294, (Point(row=13, col=16), 2): 8757930670640915056, (Point(row=13, col=17), 1): 5164392181106205417, (Point(row=13, col=17), 2): 5028229874313928315, (Point(row=13, col=18), 1): 745951469593936991, (Point(row=13, col=18), 2): 7863235812603636851, (Point(row=13, col=19), 1): 7015853419204749377, (Point(row=13, col=19), 2): 892712478335003348, (Point(row=14, col=1), 1): 2773262347422966106, (Point(row=14, col=1), 2): 1354051903744075677, (Point(row=14, col=2), 1): 9203138413833414478, (Point(row=14, col=2), 2): 7573334757726764628, (Point(row=14, col=3), 1): 2595515700034824530, (Point(row=14, col=3), 2): 935965560712448542, (Point(row=14, col=4), 1): 8227582430606217533, (Point(row=14, col=4), 2): 2035806753462985518, (Point(row=14, col=5), 1): 2625387496329510667, (Point(row=14, col=5), 2): 7444942779522099665, (Point(row=14, col=6), 1): 1371081845641586778, (Point(row=14, col=6), 2): 1815365427313462874, (Point(row=14, col=7), 1): 8163503469781925572, (Point(row=14, col=7), 2): 4057162936737793116, (Point(row=14, col=8), 1): 3227896442530321000, (Point(row=14, col=8), 2): 472133075599701720, (Point(row=14, col=9), 1): 6807092817367232840, (Point(row=14, col=9), 2): 4367123300124753493, (Point(row=14, col=10), 1): 3609948872692460063, (Point(row=14, col=10), 2): 3438882123688521472, (Point(row=14, col=11), 1): 5353986541119429986, (Point(row=14, col=11), 2): 3807291318417134537, (Point(row=14, col=12), 1): 1246805290622195623, (Point(row=14, col=12), 2): 9151325866516662209, (Point(row=14, col=13), 1): 2777651228651436680, (Point(row=14, col=13), 2): 5115103006089109812, (Point(row=14, col=14), 1): 4188311163408291767, (Point(row=14, col=14), 2): 4072589073185631671, (Point(row=14, col=15), 1): 8722149429285465862, (Point(row=14, col=15), 2): 5134077324857058209, (Point(row=14, col=16), 1): 7470491031708255802, (Point(row=14, col=16), 2): 624878254358722621, (Point(row=14, col=17), 1): 5919434229145804317, (Point(row=14, col=17), 2): 4992335911544705492, (Point(row=14, col=18), 1): 5867255578223311842, (Point(row=14, col=18), 2): 6232275327302931692, (Point(row=14, col=19), 1): 8852364652528270102, (Point(row=14, col=19), 2): 4797207295784892825, (Point(row=15, col=1), 1): 7724284371626624864, (Point(row=15, col=1), 2): 7877171730455876851, (Point(row=15, col=2), 1): 1177925311095901852, (Point(row=15, col=2), 2): 7817415815188748449, (Point(row=15, col=3), 1): 6970424979352280179, (Point(row=15, col=3), 2): 8743907216611557565, (Point(row=15, col=4), 1): 5488667594137485106, (Point(row=15, col=4), 2): 6501795981494695337, (Point(row=15, col=5), 1): 5668841773166523189, (Point(row=15, col=5), 2): 2365795305247141798, (Point(row=15, col=6), 1): 1176507074119402046, (Point(row=15, col=6), 2): 8647043245760091082, (Point(row=15, col=7), 1): 630534739735737703, (Point(row=15, col=7), 2): 6095113805308964102, (Point(row=15, col=8), 1): 5548421220287188707, (Point(row=15, col=8), 2): 6060683519504085821, (Point(row=15, col=9), 1): 5696720039067505824, (Point(row=15, col=9), 2): 2536674158229949368, (Point(row=15, col=10), 1): 1812681280476160521, (Point(row=15, col=10), 2): 7265872781303481040, (Point(row=15, col=11), 1): 2640693439966269158, (Point(row=15, col=11), 2): 987568851443960514, (Point(row=15, col=12), 1): 4319113745579819787, (Point(row=15, col=12), 2): 642032730552759749, (Point(row=15, col=13), 1): 3255395261493009397, (Point(row=15, col=13), 2): 3399384677467544498, (Point(row=15, col=14), 1): 4232878084198606693, (Point(row=15, col=14), 2): 7786022892721851918, (Point(row=15, col=15), 1): 1137181123011293673, (Point(row=15, col=15), 2): 7949440033031598925, (Point(row=15, col=16), 1): 3533983619711247339, (Point(row=15, col=16), 2): 4573391692393939544, (Point(row=15, col=17), 1): 200210978504254194, (Point(row=15, col=17), 2): 4511615267856613823, (Point(row=15, col=18), 1): 368080830293543225, (Point(row=15, col=18), 2): 2181786316688528182, (Point(row=15, col=19), 1): 5570500123864967565, (Point(row=15, col=19), 2): 3441838474151107866, (Point(row=16, col=1), 1): 767819663903925265, (Point(row=16, col=1), 2): 5072207912543350730, (Point(row=16, col=2), 1): 1597183640560374665, (Point(row=16, col=2), 2): 3834859225726864562, (Point(row=16, col=3), 1): 6186644869382185443, (Point(row=16, col=3), 2): 7844892363949409393, (Point(row=16, col=4), 1): 1529087654273071519, (Point(row=16, col=4), 2): 4560024925429282331, (Point(row=16, col=5), 1): 3677340863019583973, (Point(row=16, col=5), 2): 6834064504551248997, (Point(row=16, col=6), 1): 1833323134812055811, (Point(row=16, col=6), 2): 2466019100038565887, (Point(row=16, col=7), 1): 8464858926433575254, (Point(row=16, col=7), 2): 4661707272359485474, (Point(row=16, col=8), 1): 4377405379962554994, (Point(row=16, col=8), 2): 1463324914905300023, (Point(row=16, col=9), 1): 141669599032617529, (Point(row=16, col=9), 2): 6195884353994144619, (Point(row=16, col=10), 1): 7090976469332249743, (Point(row=16, col=10), 2): 429926140135039853, (Point(row=16, col=11), 1): 7917534980535235506, (Point(row=16, col=11), 2): 2205476484303999699, (Point(row=16, col=12), 1): 8693451716958989664, (Point(row=16, col=12), 2): 9186860436653399841, (Point(row=16, col=13), 1): 6806126240353942866, (Point(row=16, col=13), 2): 4092566193938593556, (Point(row=16, col=14), 1): 7680498753323745148, (Point(row=16, col=14), 2): 5099145326875776465, (Point(row=16, col=15), 1): 4576770972852240930, (Point(row=16, col=15), 2): 472183088160691676, (Point(row=16, col=16), 1): 6459492537011057347, (Point(row=16, col=16), 2): 8415060569714314785, (Point(row=16, col=17), 1): 7455781131109495650, (Point(row=16, col=17), 2): 2983392121854158742, (Point(row=16, col=18), 1): 1921471032732681283, (Point(row=16, col=18), 2): 8633183558910842589, (Point(row=16, col=19), 1): 1579082116465327574, (Point(row=16, col=19), 2): 5243387093199512891, (Point(row=17, col=1), 1): 8061435912060503915, (Point(row=17, col=1), 2): 4256356608123521483, (Point(row=17, col=2), 1): 1131592377173497478, (Point(row=17, col=2), 2): 1351344459186299409, (Point(row=17, col=3), 1): 6836314011800425958, (Point(row=17, col=3), 2): 4042092772560294310, (Point(row=17, col=4), 1): 2157672389737342213, (Point(row=17, col=4), 2): 9062869196334574586, (Point(row=17, col=5), 1): 9209539878632938123, (Point(row=17, col=5), 2): 7685573288287509576, (Point(row=17, col=6), 1): 8865558969031226672, (Point(row=17, col=6), 2): 9214846649308684639, (Point(row=17, col=7), 1): 7541404829661694486, (Point(row=17, col=7), 2): 611481125947491974, (Point(row=17, col=8), 1): 400254266422670016, (Point(row=17, col=8), 2): 2965020440505078818, (Point(row=17, col=9), 1): 5297630264248364345, (Point(row=17, col=9), 2): 6394867058965373596, (Point(row=17, col=10), 1): 7066797470282560415, (Point(row=17, col=10), 2): 520994171623777872, (Point(row=17, col=11), 1): 8922531366932912856, (Point(row=17, col=11), 2): 7940452208900129325, (Point(row=17, col=12), 1): 3077970396063004094, (Point(row=17, col=12), 2): 7639477308915629166, (Point(row=17, col=13), 1): 8243564795684110167, (Point(row=17, col=13), 2): 320982722807163389, (Point(row=17, col=14), 1): 9143523636315015713, (Point(row=17, col=14), 2): 4384975553613394397, (Point(row=17, col=15), 1): 5135580822245744791, (Point(row=17, col=15), 2): 3658106926172602928, (Point(row=17, col=16), 1): 1482402319749046794, (Point(row=17, col=16), 2): 2893398439703283560, (Point(row=17, col=17), 1): 4787981898732493291, (Point(row=17, col=17), 2): 4655398084026101605, (Point(row=17, col=18), 1): 5767079464111574799, (Point(row=17, col=18), 2): 2781460909149130028, (Point(row=17, col=19), 1): 6597630183406014107, (Point(row=17, col=19), 2): 6730013495948956061, (Point(row=18, col=1), 1): 2803881425323665116, (Point(row=18, col=1), 2): 2463797384378610275, (Point(row=18, col=2), 1): 2794655832549481702, (Point(row=18, col=2), 2): 1669101452970713267, (Point(row=18, col=3), 1): 614299220754809235, (Point(row=18, col=3), 2): 3451751138550605429, (Point(row=18, col=4), 1): 6221948812590252683, (Point(row=18, col=4), 2): 1279307806139497922, (Point(row=18, col=5), 1): 733569892152018045, (Point(row=18, col=5), 2): 7364984761116159917, (Point(row=18, col=6), 1): 448383993842870961, (Point(row=18, col=6), 2): 129619736144613976, (Point(row=18, col=7), 1): 3397309910501355329, (Point(row=18, col=7), 2): 7845279135503342902, (Point(row=18, col=8), 1): 2065192835427349668, (Point(row=18, col=8), 2): 3680121029880239296, (Point(row=18, col=9), 1): 1401023643202196157, (Point(row=18, col=9), 2): 5434588379063981500, (Point(row=18, col=10), 1): 67745175847071543, (Point(row=18, col=10), 2): 5297232379803478185, (Point(row=18, col=11), 1): 9176199013739862279, (Point(row=18, col=11), 2): 1889397638428433630, (Point(row=18, col=12), 1): 8689469688729811152, (Point(row=18, col=12), 2): 6250058096806078997, (Point(row=18, col=13), 1): 518590469000375354, (Point(row=18, col=13), 2): 8633722984025048054, (Point(row=18, col=14), 1): 5998212610008216863, (Point(row=18, col=14), 2): 6755394622985873051, (Point(row=18, col=15), 1): 8607327312264015656, (Point(row=18, col=15), 2): 2825718670281288797, (Point(row=18, col=16), 1): 223085381522744823, (Point(row=18, col=16), 2): 8227025073406980954, (Point(row=18, col=17), 1): 8667209858827202891, (Point(row=18, col=17), 2): 342046128905942498, (Point(row=18, col=18), 1): 2703589165602475233, (Point(row=18, col=18), 2): 4269463498836643006, (Point(row=18, col=19), 1): 7254794649311180517, (Point(row=18, col=19), 2): 6117565458110146323, (Point(row=19, col=1), 1): 6030605843733933210, (Point(row=19, col=1), 2): 4148002746604609367, (Point(row=19, col=2), 1): 3438074632011672444, (Point(row=19, col=2), 2): 598161291564067390, (Point(row=19, col=3), 1): 6504824548481619886, (Point(row=19, col=3), 2): 7057730423853575257, (Point(row=19, col=4), 1): 841667386469312518, (Point(row=19, col=4), 2): 5567854235926872923, (Point(row=19, col=5), 1): 8534799306958449628, (Point(row=19, col=5), 2): 711998175236969326, (Point(row=19, col=6), 1): 3961903707475001948, (Point(row=19, col=6), 2): 3606273735379653742, (Point(row=19, col=7), 1): 522065080542823436, (Point(row=19, col=7), 2): 8228338073499208877, (Point(row=19, col=8), 1): 5148697517014572280, (Point(row=19, col=8), 2): 2197924651264579980, (Point(row=19, col=9), 1): 5094418096662934638, (Point(row=19, col=9), 2): 183619838593838589, (Point(row=19, col=10), 1): 7591037813170688511, (Point(row=19, col=10), 2): 2531967660500907918, (Point(row=19, col=11), 1): 3565634386773941175, (Point(row=19, col=11), 2): 3731730528537394647, (Point(row=19, col=12), 1): 1385426157833446212, (Point(row=19, col=12), 2): 7210631923797770812, (Point(row=19, col=13), 1): 8375599338570666211, (Point(row=19, col=13), 2): 1400777486183314542, (Point(row=19, col=14), 1): 5893715567907126288, (Point(row=19, col=14), 2): 1751923641861001330, (Point(row=19, col=15), 1): 1814143243546687662, (Point(row=19, col=15), 2): 3206226143420083996, (Point(row=19, col=16), 1): 386359770617631512, (Point(row=19, col=16), 2): 1020886174148615249, (Point(row=19, col=17), 1): 1653220343529331268, (Point(row=19, col=17), 2): 4791171220912322868, (Point(row=19, col=18), 1): 7974445220448632939, (Point(row=19, col=18), 2): 1766588994139096148, (Point(row=19, col=19), 1): 2553479001069707563, (Point(row=19, col=19), 2): 5355549353071061431}\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"## Fast Game Environment","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom collections import defaultdict\n\nclass FastBoard:\n    \"\"\"Optimized board using numpy arrays\"\"\"\n    def __init__(self, num_rows, num_cols):\n        self.num_rows = num_rows\n        self.num_cols = num_cols\n        # Use numpy arrays: 0=empty, 1=black, 2=white\n        self.grid = np.zeros((num_rows, num_cols), dtype=np.int8)\n        self._hash = 0\n        \n    def copy(self):\n        \"\"\"Fast shallow copy with numpy array copy\"\"\"\n        new_board = FastBoard.__new__(FastBoard)\n        new_board.num_rows = self.num_rows\n        new_board.num_cols = self.num_cols\n        new_board.grid = self.grid.copy()  # Fast numpy copy\n        new_board._hash = self._hash\n        return new_board\n    \n    def place_stone(self, player, row, col):\n        \"\"\"Place stone and handle captures\"\"\"\n        self.grid[row, col] = player\n        point = Point(row+1, col+1)\n        self._hash ^= HASH_CODE[point, player]\n        \n        # Check for captures of opponent stones\n        opponent = 3 - player  # Toggles between 1 and 2\n        for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n            nr, nc = row + dr, col + dc\n            if self._is_on_grid(nr, nc) and self.grid[nr, nc] == opponent:\n                if self._count_liberties(nr, nc) == 0:\n                    self._remove_group(nr, nc)\n    \n    def _is_on_grid(self, row, col):\n        return 0 <= row < self.num_rows and 0 <= col < self.num_cols\n    \n    def _count_liberties(self, row, col):\n        \"\"\"Count liberties of group using flood fill\"\"\"\n        color = self.grid[row, col]\n        if color == 0:\n            return 0\n        \n        visited = np.zeros_like(self.grid, dtype=bool)\n        liberty_count = 0\n        stack = [(row, col)]\n        \n        while stack:\n            r, c = stack.pop()\n            if visited[r, c]:\n                continue\n            visited[r, c] = True\n            \n            for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n                nr, nc = r + dr, c + dc\n                if not self._is_on_grid(nr, nc):\n                    continue\n                    \n                if self.grid[nr, nc] == 0:\n                    liberty_count += 1\n                elif self.grid[nr, nc] == color and not visited[nr, nc]:\n                    stack.append((nr, nc))\n        \n        return liberty_count\n    \n    def _remove_group(self, row, col):\n        \"\"\"Remove a captured group\"\"\"\n        color = self.grid[row, col]\n        stack = [(row, col)]\n        visited = set()\n        \n        while stack:\n            r, c = stack.pop()\n            if (r, c) in visited:\n                continue\n            visited.add((r, c))\n            \n            if not self._is_on_grid(r, c) or self.grid[r, c] != color:\n                continue\n            \n            self.grid[r, c] = 0\n            point = Point(row=r+1, col=c+1)\n            self._hash ^= HASH_CODE[point, color]\n            \n            for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n                stack.append((r + dr, c + dc))\n    \n    def zobrist_hash(self):\n        return self._hash\n    \n    def get(self, row, col):\n        return self.grid[row, col]\n\n\nclass FastGameState:\n    \"\"\"Optimized game state\"\"\"\n    def __init__(self, board, next_player, previous_hash=None, last_move = None, second_last_move = None):\n        self.board = board\n        self.next_player = next_player  # 1 for black, 2 for white\n        self.previous_hashes = set()\n        if previous_hash is not None:\n            self.previous_hashes.add(previous_hash)\n        self.last_move = last_move\n        self.second_last_move = second_last_move\n    \n    def apply_move(self, move):\n        \"\"\"Apply move and return new state (only copies when needed)\"\"\"\n        if move.is_play:\n            point = move.point\n            row = point.row - 1\n            col = point.col - 1\n            new_board = self.board.copy()  # Fast numpy copy\n            new_board.place_stone(self.next_player, row, col)\n        else:\n            new_board = self.board.copy()\n        \n        new_state = FastGameState(new_board, 3 - self.next_player, \n                                  self.board.zobrist_hash(), move, self.last_move)\n        new_state.previous_hashes = self.previous_hashes.copy()\n        new_state.previous_hashes.add(self.board.zobrist_hash())\n        \n        return new_state\n\n    def is_over(self):\n        if self.last_move is None:\n            return False\n        if self.last_move.is_resign:\n            return True\n        if self.second_last_move is None:\n            return False\n        return self.last_move.is_pass and self.second_last_move.is_pass\n    \n    def is_valid_move(self, move):\n        \"\"\"Check if move is valid\"\"\"\n        if self.is_over():\n            return False\n        if move.is_pass or move.is_resign:\n            return True\n\n        point = move.point\n        row = point.row - 1\n        col = point.col - 1\n\n        if self.board.get(row, col) != 0:\n            return False\n        \n        # Quick check: simulate move\n        test_board = self.board.copy()\n        test_board.place_stone(self.next_player, row, col)\n        \n        # Check for self-capture\n        if test_board._count_liberties(row, col) == 0:\n            return False\n        \n        # Check for ko violation\n        if test_board.zobrist_hash() in self.previous_hashes:\n            return False\n        \n        return True\n    \n    def legal_moves(self):\n        \"\"\"Return all legal moves as (row, col) tuples\"\"\"\n        legal = []\n        for row in range(self.board.num_rows):\n            for col in range(self.board.num_cols):\n                move = Move.play(Point(row+1, col+1))\n                if self.is_valid_move(move):\n                    legal.append(move)\n        legal.append(Move.pass_turn())\n        legal.append(Move.resign())\n        return legal\n\n    def winner(self):\n        if not self.is_over():\n            return None\n        if self.last_move.is_resign:\n            return self.next_player\n        game_result = compute_game_result(self)\n        return game_result.winner\n    \n    @classmethod\n    def new_game(cls, board_size=19):\n        board = FastBoard(board_size, board_size)\n        return FastGameState(board, 1)  # Black plays first","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:43:24.759573Z","iopub.execute_input":"2025-12-18T18:43:24.759943Z","iopub.status.idle":"2025-12-18T18:43:24.786648Z","shell.execute_reply.started":"2025-12-18T18:43:24.759921Z","shell.execute_reply":"2025-12-18T18:43:24.785677Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"class FastTerritory:\n    \"\"\"Fast territory evaluation results\"\"\"\n    __slots__ = ['num_black_territory', 'num_white_territory', \n                 'num_black_stones', 'num_white_stones', \n                 'num_dame', 'dame_points']\n    \n    def __init__(self):\n        self.num_black_territory = 0\n        self.num_white_territory = 0\n        self.num_black_stones = 0\n        self.num_white_stones = 0\n        self.num_dame = 0\n        self.dame_points = []\n\nclass FastGameResult:\n    \"\"\"Game result with score calculation\"\"\"\n    __slots__ = ['b', 'w', 'komi']\n    \n    def __init__(self, b, w, komi=7.5):\n        self.b = b\n        self.w = w\n        self.komi = komi\n    \n    @property\n    def winner(self):\n        \"\"\"Return 1 for black, 2 for white, 0 for tie\"\"\"\n        if self.b > self.w + self.komi:\n            return 1  # Black\n        if self.b < self.w + self.komi:\n            return 2  # White\n        return 0  # Tie\n    \n    @property\n    def winning_margin(self):\n        w = self.w + self.komi\n        return abs(self.b - w)\n    \n    def __str__(self):\n        w = self.w + self.komi\n        if self.b > w:\n            return f'B+{self.b - w:.1f}'\n        return f'W+{w - self.b:.1f}'\n\ndef evaluate_territory_fast(board):\n    \"\"\"Optimized territory evaluation using numpy and flood fill\n    \n    Returns Territory object with stone and territory counts\n    \"\"\"\n    grid = board.grid\n    rows, cols = grid.shape\n    \n    # Status: 0=unvisited, 1=black stone, 2=white stone, \n    # 3=black territory, 4=white territory, 5=dame\n    status = np.zeros((rows, cols), dtype=np.int8)\n    status[grid > 0] = grid[grid > 0]  # Copy stones\n    \n    territory = Territory()\n    \n    # Count stones directly from grid\n    territory.num_black_stones = np.sum(grid == 1)\n    territory.num_white_stones = np.sum(grid == 2)\n    \n    # Flood fill empty regions\n    for r in range(rows):\n        for c in range(cols):\n            if status[r, c] == 0:  # Empty and unvisited\n                points, borders = _collect_region_fast(r, c, grid, status)\n                \n                # Determine territory ownership\n                if len(borders) == 1:\n                    # Single color border = territory\n                    owner = borders.pop()\n                    if owner == 1:\n                        territory.num_black_territory += len(points)\n                        fill_value = 3\n                    else:\n                        territory.num_white_territory += len(points)\n                        fill_value = 4\n                else:\n                    # Multiple colors or no border = dame\n                    territory.num_dame += len(points)\n                    territory.dame_points.extend(points)\n                    fill_value = 5\n                \n                # Mark all points in region\n                for pr, pc in points:\n                    status[pr, pc] = fill_value\n    \n    return territory\n\n\ndef _collect_region_fast(start_r, start_c, grid, status):\n    \"\"\"Fast flood fill using stack instead of recursion\n    \n    Args:\n        start_r, start_c: Starting position\n        grid: Board grid (numpy array)\n        status: Status tracking array\n        \n    Returns:\n        (points, borders): List of (row, col) tuples and set of border colors\n    \"\"\"\n    rows, cols = grid.shape\n    points = []\n    borders = set()\n    \n    # Stack-based flood fill (much faster than recursion)\n    stack = [(start_r, start_c)]\n    visited = np.zeros((rows, cols), dtype=bool)\n    \n    while stack:\n        r, c = stack.pop()\n        \n        if visited[r, c]:\n            continue\n        visited[r, c] = True\n        \n        points.append((r, c))\n        \n        # Check all 4 neighbors\n        for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n            nr, nc = r + dr, c + dc\n            \n            if not (0 <= nr < rows and 0 <= nc < cols):\n                continue\n            \n            neighbor_value = grid[nr, nc]\n            \n            if neighbor_value == 0 and not visited[nr, nc]:\n                # Empty space, continue flood fill\n                stack.append((nr, nc))\n            elif neighbor_value > 0:\n                # Stone found, add to borders\n                borders.add(neighbor_value)\n    \n    return points, borders\n\n\ndef compute_game_result_fast(game_state, komi=7.5):\n    \"\"\"Compute final game result\n    \n    Args:\n        game_state: FastGameState object\n        komi: Komi value (default 7.5 for standard rules)\n        \n    Returns:\n        GameResult object\n    \"\"\"\n    territory = evaluate_territory_fast(game_state.board)\n    \n    black_score = territory.num_black_territory + territory.num_black_stones\n    white_score = territory.num_white_territory + territory.num_white_stones\n    \n    return GameResult(black_score, white_score, komi)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:43:29.540411Z","iopub.execute_input":"2025-12-18T18:43:29.540733Z","iopub.status.idle":"2025-12-18T18:43:29.557868Z","shell.execute_reply.started":"2025-12-18T18:43:29.540711Z","shell.execute_reply":"2025-12-18T18:43:29.556945Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import random\nimport time\nclass FastRandomBot:\n    def __init__(self, player):\n        self.player = player\n    def play_move(self, game_state):\n        legal_moves = game_state.legal_moves()\n        random_move = random.choice(legal_moves)\n        new_game_state = game_state.apply_move(random_move)\n        return new_game_state, 3 - self.player\n\ndef play_game():\n    game_state = FastGameState.new_game()\n    \n    agent = FastRandomBot(player = 1)\n    opponent = FastRandomBot(player = 2)\n    next_player = 1\n    while not game_state.is_over():\n        if next_player == 1:\n            game_state, next_player = agent.play_move(game_state)\n        else:\n            game_state, next_player = opponent.play_move(game_state)\n    return game_state.winner()\n\nstart = time.time()\nfor _ in range(10):\n    winner = play_game()\n    print(winner)\nend = time.time()\n\nprint(f\"time elapsed {end - start} seconds\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4 Plane Encoder\n\nOriginal AlphaGo uses a 48 plane encoder, we use 4 plane encoder, which is also mentioned in the paper.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n\"\"\"\nFeature name            num of planes   Description\nStone colour            3               Player stone / opponent stone / empty\nOnes                    1               A constant plane filled with 1\n\"\"\"\n\nFEATURE_OFFSETS = {\n    \"stone_color\": 0,\n    \"ones\": 3,\n    \"current_player_color\": 4,\n    \"legal_moves\": 5\n}\n\n\ndef offset(feature):\n    return FEATURE_OFFSETS[feature]\n\n# TODO: I need to change the Four plane encoder, just because I have changed the environment\nclass FourplaneEncoder:\n    def __init__(self, board_size=(19, 19), use_player_plane=True, use_legal_moves=True):\n        self.board_width, self.board_height = board_size\n        self.use_player_plane = use_player_plane\n        self.use_legal_moves = use_legal_moves\n        self.num_planes = 4 + use_player_plane + use_legal_moves\n\n    def name(self):\n        return 'fourplane'\n\n    def encode(self, game_state):\n        board_tensor = np.zeros((self.num_planes, self.board_height, self.board_width))\n        \n        # Set empty cells plane (default to empty)\n        board_tensor[offset(\"stone_color\") + 2] = 1\n        \n        # Iterate over occupied points only (much faster for sparse boards)\n        next_player = game_state.next_player\n        opponent = next_player.other\n        stone_color_offset = offset(\"stone_color\")\n        \n        for point, go_string in game_state.board._grid.items():\n            if go_string is None:\n                continue\n            r = point.row - 1\n            c = point.col - 1\n            if go_string.color == next_player:\n                board_tensor[stone_color_offset][r][c] = 1\n                board_tensor[stone_color_offset + 2][r][c] = 0  # Not empty\n            elif go_string.color == opponent:\n                board_tensor[stone_color_offset + 1][r][c] = 1\n                board_tensor[stone_color_offset + 2][r][c] = 0  # Not empty\n        \n        # Set ones plane once (moved outside loop)\n        board_tensor[offset(\"ones\")] = 1\n        \n        # Set player plane once (moved outside loop)\n        if self.use_player_plane and next_player == Player.black:\n            board_tensor[offset(\"current_player_color\")] = 1\n        \n        # Set legal moves - optimized inline computation to avoid expensive deep copies\n        if self.use_legal_moves:\n            if not game_state.is_over():\n                legal_moves_offset = offset(\"legal_moves\")\n                board = game_state.board\n                \n                # Fast inline legal move checking without deep copies\n                for row in range(1, board.num_rows + 1):\n                    for col in range(1, board.num_cols + 1):\n                        point = Point(row, col)\n                        \n                        # Fast check: point must be empty\n                        if board._grid.get(point) is not None:\n                            continue\n                        \n                        # Check self-capture without deep copy\n                        has_liberty = False\n                        would_capture = False\n                        friendly_strings = []\n                        \n                        for neighbor in point.neighbors():\n                            if not board.is_on_grid(neighbor):\n                                continue\n                            neighbor_string = board._grid.get(neighbor)\n                            if neighbor_string is None:\n                                has_liberty = True\n                                break\n                            elif neighbor_string.color == next_player:\n                                friendly_strings.append(neighbor_string)\n                            else:  # opponent string\n                                if neighbor_string.num_liberties == 1:\n                                    would_capture = True\n                        \n                        # If has liberty, not self-capture\n                        if not has_liberty:\n                            # Check if all friendly strings would have no liberties\n                            if friendly_strings and all(s.num_liberties == 1 for s in friendly_strings):\n                                if not would_capture:\n                                    continue  # Self-capture, skip\n                        \n                        # Check ko violation - simplified heuristic for performance\n                        # Full ko check requires deep copy, so we use a fast heuristic:\n                        # If last move captured exactly one stone and we're trying to recapture\n                        # at that same position, it's likely a ko violation\n                        if would_capture and game_state.last_move and game_state.last_move.is_play:\n                            # Check if we're trying to play at the last move position\n                            # (which would be recapturing after a single-stone capture)\n                            if point == game_state.last_move.point:\n                                # Count how many stones we'd capture\n                                captured_stones = 0\n                                for neighbor in point.neighbors():\n                                    if not board.is_on_grid(neighbor):\n                                        continue\n                                    neighbor_string = board._grid.get(neighbor)\n                                    if neighbor_string and neighbor_string.color == opponent:\n                                        if neighbor_string.num_liberties == 1:\n                                            captured_stones += len(neighbor_string.stones)\n                                # If capturing exactly one stone at last move position, likely ko\n                                if captured_stones == 1:\n                                    continue  # Likely ko violation, skip\n                        \n                        # Valid move - set it\n                        r = row - 1\n                        c = col - 1\n                        board_tensor[legal_moves_offset][r][c] = 1\n\n        return board_tensor\n\n    def ones(self):\n        return np.ones((1, self.board_height, self.board_width))\n\n    def zeros(self):\n        return np.zeros((1, self.board_height, self.board_width))\n\n    def encode_point(self, point):\n        return self.board_width * (point.row - 1) + (point.col - 1)\n\n    def decode_point_index(self, index):\n        row = index // self.board_width\n        col = index % self.board_width\n        return Point(row=row + 1, col=col + 1)\n\n    def num_points(self):\n        return self.board_width * self.board_height\n\n    def shape(self):\n        return self.num_planes, self.board_height, self.board_width\n\n\ndef create(board_size):\n    return FourplaneEncoder(board_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T12:02:44.335863Z","iopub.execute_input":"2025-11-25T12:02:44.336368Z","iopub.status.idle":"2025-11-25T12:02:44.350647Z","shell.execute_reply.started":"2025-11-25T12:02:44.336344Z","shell.execute_reply":"2025-11-25T12:02:44.350060Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Supervised Learning Policy Network\n\n - Convolution layer with rectifier non-linearities.\n - CNN with 13 layers\n - Final softmax applied to legal moves\n - Data has been split into 4:1 train to test ratio. (In AlphaGo it is 28:1)\n - Pass moves has been excluded from the dataset\n - All 8 reflections and rotations has been applied and precomputed. We randomly sample mini batch from the augmented sample\n - Asynchronous stochastic gradient descent to minimize the log likelihood\n - Learning parameter is initialized to 0.03 and halved every 30k steps. (In AlphaGo, learning rate is 0.003 and halved every 80 mil training steps)\n - mini batch size of 16 as mentioned in the paper\n - zero momentum","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch\n\nclass SLPolicyNetwork(nn.Module):\n    def __init__(self, features=5, filters=192):\n        super(SLPolicyNetwork, self).__init__()\n        self.features = features\n        self.filters = filters\n        self.first_layer = nn.Conv2d(self.features, self.filters, kernel_size=5, stride=1, padding=2)\n\n        self.hidden_layers = nn.ModuleList([\n            nn.Conv2d(self.filters, self.filters, kernel_size=3, stride=1, padding=1)\n            for _ in range(11)\n        ])\n\n        self.final_layer = nn.Conv2d(self.filters, 1, kernel_size=1, stride=1)\n\n    def forward(self, x):\n        # extract legal moves from the data tensor\n        legal_moves = x[:, 5, :, :]\n        x = F.relu(self.first_layer(x))\n        for layer in self.hidden_layers:\n            x = F.relu(layer(x))\n        # Logits are the unnormalized scores output by the network for each possible move before softmax\n        policy_logits = self.final_layer(x)  # (batch, 1, board_size, board_size)\n\n        # apply legal move mask\n        # Reshape and apply log_softmax for NLLLoss compatibility as per Alphago paper\n        batch_size = policy_logits.size(0)\n        policy_logits = policy_logits.view(batch_size, -1)\n        legal_move_mask = legal_moves.view(batch_size, -1)\n        # apply log softmax to only legal moves\n        masked_policy_logits = torch.where(\n            legal_move_mask.bool(),\n            policy_logits,\n            torch.full_like(policy_logits, float('-inf'))\n        )\n        log_probs = F.log_softmax(masked_policy_logits, dim=1)\n        return log_probs","metadata":{"id":"ZdWFRyo85o6w","trusted":true,"execution":{"iopub.status.busy":"2025-11-25T12:03:00.134593Z","iopub.execute_input":"2025-11-25T12:03:00.135374Z","iopub.status.idle":"2025-11-25T12:03:00.141732Z","shell.execute_reply.started":"2025-11-25T12:03:00.135338Z","shell.execute_reply":"2025-11-25T12:03:00.141208Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Supervised Learning Policy Trainer","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\n\nclass SLPolicyTrainer:\n    def __init__(self, model):\n        # initialize hyperparams\n        self.model = model\n        self.optimizer = None\n        self.criterion = None\n        self.scheduler = None\n\n    def initialize(self):\n        self.optimizer = optim.SGD(\n            params = self.model.parameters(),\n            lr = 0.03\n        )\n        self.scheduler = StepLR(self.optimizer, step_size=30000, gamma=0.5)\n        self.criterion = nn.NLLLoss()\n        return\n    def train(self, loader):\n        self.model.train()\n        total_loss = 0\n        correct_predictions = 0\n        total_sample = 0\n        for (x, y) in loader:\n            # Cast input to float32\n            x = x.to(torch.float32)\n            self.optimizer.zero_grad()\n            log_probs = self.model(x)\n\n            loss = self.criterion(log_probs, y)\n\n            loss.backward()\n            self.optimizer.step()\n            self.scheduler.step()\n\n            total_loss += loss.item()\n            total_sample += y.size(0)\n            prediction = log_probs.argmax(dim=1)\n            correct_predictions += (prediction == y).sum().item()\n\n        avg_loss = total_loss / len(loader)\n        acc = correct_predictions / total_sample\n\n        return avg_loss, acc\n    def evaluate(self, loader):\n        self.model.eval()\n        total_loss = 0\n        total_sample = 0\n        correct_predictions = 0\n        with torch.no_grad():\n            for (x, y) in loader:\n                # Cast input to float32\n                x = x.to(torch.float32)\n                log_probs = self.model(x)\n                loss = self.criterion(log_probs, y)\n                prediction = log_probs.argmax(dim=1)\n                total_loss += loss.item()\n                total_sample += y.size(0)\n                correct_predictions += (prediction == y).sum().item()\n\n\n        avg_loss = total_loss / len(loader)\n        acc = correct_predictions / total_sample\n        return avg_loss, acc","metadata":{"id":"rc-b32Xl7sHa","trusted":true,"execution":{"iopub.status.busy":"2025-11-22T18:33:51.839672Z","iopub.execute_input":"2025-11-22T18:33:51.839921Z","iopub.status.idle":"2025-11-22T18:33:51.863099Z","shell.execute_reply.started":"2025-11-22T18:33:51.839901Z","shell.execute_reply":"2025-11-22T18:33:51.862084Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## DataLoader for Go","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.utils.data as td\n\n__all__ = [\n    'GoDataLoader'\n]\n\nclass GoDataLoader:\n    def __init__(self, feature_path, label_path = None):\n        self.feature_path = feature_path\n        self.label_path = label_path\n\n    def load_data(self):\n        features = np.load(self.feature_path)\n        features_tensor = torch.from_numpy(features)\n\n        if self.label_path:\n            labels = np.load(self.label_path)\n            labels_tensor = torch.from_numpy(labels).to(torch.int64) # Cast labels to torch.int64\n            # this dataset can be directly used with torch's DataLoader\n            dataset = td.TensorDataset(features_tensor, labels_tensor)\n        else:\n            dataset = td.TensorDataset(features_tensor)\n        return dataset","metadata":{"id":"fPmtmIWR7zXz","trusted":true,"execution":{"iopub.status.busy":"2025-11-22T18:33:51.863998Z","iopub.execute_input":"2025-11-22T18:33:51.864319Z","iopub.status.idle":"2025-11-22T18:33:51.885493Z","shell.execute_reply.started":"2025-11-22T18:33:51.864294Z","shell.execute_reply":"2025-11-22T18:33:51.884621Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Loop of Supervised Learning Policy","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\n\nprint(\"Load model\")\nmodel = SLPolicyNetwork(features=6)\nnum_of_epochs = 10\n\n# prepare the dataset\nprint(\"fetch and load data\")\ntraining_feature_path = '/kaggle/input/alphago-kgs-200k/KGS-2019_04-19-1255-_train_features.npy'\ntraining_label_path = '/kaggle/input/alphago-kgs-200k/KGS-2019_04-19-1255-_train_labels.npy'\ntest_feature_path = '/kaggle/input/alphago-kgs-200k/KGS-2019_04-19-1255-_test_features.npy'\ntest_label_path = '/kaggle/input/alphago-kgs-200k/KGS-2019_04-19-1255-_test_labels.npy'\ntraining_dataset = GoDataLoader(training_feature_path, training_label_path).load_data()\ntest_dataset = GoDataLoader(test_feature_path, test_label_path).load_data()\n\n# load the dataset to a loader\n# this is what we will pass to our Trainer\ntraining_loader = DataLoader(training_dataset, batch_size=16, shuffle=True, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n\n# load the trainer\ntrainer = SLPolicyTrainer(model)\ntrainer.initialize()\n\nfor epoch in range(num_of_epochs):\n    training_loss, training_acc = trainer.train(training_loader)\n    test_loss, test_acc = trainer.evaluate(test_loader)\n    print(f\"epoch: {epoch}, training loss: {training_loss}, training acc: {training_acc}, test loss: {test_loss}, test_acc: {test_acc}\")\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': trainer.optimizer.state_dict(),\n        'train_acc': training_acc,\n        'test_acc': test_acc,\n    }, f'sl_policy_epoch_{epoch}.pth')","metadata":{"id":"EvlY8kbo78Ui","outputId":"5f299c25-e68a-4dd0-917e-9a7f1d1f526f","trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-11-22T18:33:51.887402Z","iopub.execute_input":"2025-11-22T18:33:51.887632Z","iopub.status.idle":"2025-11-22T19:15:32.648042Z","shell.execute_reply.started":"2025-11-22T18:33:51.887611Z","shell.execute_reply":"2025-11-22T19:15:32.647086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check if gpu is available\n\nimport torch\n\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"CUDA device count: {torch.cuda.device_count()}\")\nif torch.cuda.is_available():\n    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T12:03:08.121378Z","iopub.execute_input":"2025-11-25T12:03:08.121615Z","iopub.status.idle":"2025-11-25T12:03:08.248508Z","shell.execute_reply.started":"2025-11-25T12:03:08.121600Z","shell.execute_reply":"2025-11-25T12:03:08.247891Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Supervised Learning Policy Agent","metadata":{}},{"cell_type":"code","source":"import torch\n\nclass SLPolicyAgent:\n    def __init__(self, model):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.model = model.to(self.device)\n        self.encoder = FourplaneEncoder()\n\n    def select_move(self, game_state):\n        assert isinstance(game_state, GameState)\n        encoded_game_state = self.encoder.encode(game_state)\n        x = torch.from_numpy(encoded_game_state)\n        x = x.unsqueeze(0)\n        x = x.to(torch.float32)\n        x = x.to(self.device)\n        log_probs = self.model(x)\n        log_probs = log_probs.squeeze(0)\n        legal_moves = game_state.legal_moves()\n        legal_moves = legal_moves[:-2]\n        if len(legal_moves) == 0:\n            return None, float('-inf')\n\n        legal_moves_mask = torch.zeros(log_probs.size(0), dtype=torch.bool, device=self.device)\n        \n        for move in legal_moves:\n            if move is not None and move.is_play:\n                encoded_point = self.encoder.encode_point(move.point)\n                legal_moves_mask[encoded_point] = True\n\n        log_probs = log_probs.masked_fill(~legal_moves_mask, float('-inf'))\n        action = torch.argmax(log_probs)\n        log_prob = log_probs[action]\n        return action, log_prob\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T12:36:44.973691Z","iopub.execute_input":"2025-11-25T12:36:44.974292Z","iopub.status.idle":"2025-11-25T12:36:44.980905Z","shell.execute_reply.started":"2025-11-25T12:36:44.974257Z","shell.execute_reply":"2025-11-25T12:36:44.980145Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Reinforcement learning of Policy Network\n\n - We use the same network as for Supervised Learning\n - We initialize the policy to be theta ( which is the supervised learning model)\n - We also use an opponent pool to randomly select opponent for mini batch training as mentioned in the paper\n - Also, using baseline default to 0 for the first pass. AlphaGo uses value network as baseline in the second pass\n - 10k episodes of 128 mini batch size\n - We add a model to the opponent pool after every 500 episodes\n - Used REINFORCE algorithm with stochastic gradient ascent for policy updates.","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nimport torch\nimport random\n\nclass RLPolicyTrainer:\n    def __init__(self, baseline = 0.0):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.model = SLPolicyNetwork(features=6).to(self.device)\n        self.opponent_pool = []\n        self.optimizer = None\n        self.baseline = baseline\n        self.episodes = 1\n        self.mini_batch = 1\n        self.board_size = 19\n        self.encoder = FourplaneEncoder()\n\n    def initialize(self):\n        model_file = torch.load('/kaggle/input/sl-policy-epoch-9/pytorch/default/1/sl_policy_epoch_9.pth', map_location=self.device)\n        self.model.load_state_dict(model_file['model_state_dict'])\n        self.optimizer = optim.SGD(params=self.model.parameters(), lr=0.03)\n        opponent_model = SLPolicyNetwork(features=6).to(self.device)\n        opponent_model.load_state_dict(model_file['model_state_dict'])\n        self.opponent_pool.append(opponent_model)\n\n    def train_batch(self):\n        opponent_model = random.choice(self.opponent_pool)\n        opponent_model.to(self.device)\n        opponent_model.eval()\n        self.model.eval()\n\n        streams = [torch.cuda.Stream(device=self.device) for _ in range(2)]\n        \n        agent = SLPolicyAgent(self.model)\n        opponent = SLPolicyAgent(opponent_model)\n        \n        expected_reward = 0\n        total_wins = 0\n        trajectories_list = []\n        rewards_list = []\n\n        for i in range(self.mini_batch):\n            print(f\"starting game: {i+1}\")\n\n            stream = streams[i % 2]\n            with torch.cuda.stream(stream):\n                game_state = GameState.new_game(self.board_size)\n                trajectory = []\n                while not game_state.is_over():\n                    if game_state.next_player == Player.black:\n                        action, _ = agent.select_move(game_state)\n                        if action is None:\n                            # player does not have any legal moves left apart from resigning or pass\n                            move = Move.resign()\n                            point = None\n                            break\n                        point = self.encoder.decode_point_index(action.item())\n                        trajectory.append((action, game_state))\n                    else:\n                        action, log_prob = opponent.select_move(game_state)\n                        if action is None:\n                            move = Move.resign()\n                            point = None\n                            break\n                        point = self.encoder.decode_point_index(action.item())\n                        \n                        if point is not None:\n                            move = Move(point)\n                        game_state = game_state.apply_move(move)\n                winner = game_state.winner()\n                print(f\"Winner: {winner}\")\n                reward = 1 if winner == Player.black else -1\n                trajectories_list.append(trajectory)\n                rewards_list.append(reward)\n\n        torch.cuda.synchronize(device=self.device)\n\n        for trajectory, reward in zip(trajectories_list, rewards_list):\n            if reward == 1:\n                total_wins += 1\n            for (action, ) in trajectory:\n                expected_reward += (reward - self.baseline) * log_prob\n\n        expected_reward /= self.mini_batch\n        win_rate = total_wins / self.mini_batch\n        \n        return expected_reward, win_rate\n\n    def train(self):\n        for i in range(self.episodes):\n            print(f\"starting episode: {i+1}\")\n            expected_reward, win_rate = self.train_batch()\n            self.model.train()\n            self.optimizer.zero_grad()\n            expected_loss = -expected_reward\n            expected_loss.backward()\n            self.optimizer.step()\n\n            torch.cuda.empty_cache()\n            \n            print(f\"expected loss: {expected_loss}, accuracy: {win_rate}\")\n            \n            if i % 500 == 0:\n                opponent_model = SLPolicyNetwork(features=6)\n                opponent_model.load_state_dict(self.model.state_dict())\n                self.opponent_pool.append(opponent_model)\n                \n        \n                    \n\nrl_trainer = RLPolicyTrainer()\nrl_trainer.initialize()\nrl_trainer.train()\n        \n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T12:37:03.576626Z","iopub.execute_input":"2025-11-25T12:37:03.577477Z","iopub.status.idle":"2025-11-25T14:21:06.482208Z","execution_failed":"2025-11-25T14:21:07.021Z"}},"outputs":[],"execution_count":null}]}